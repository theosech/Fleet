\hypertarget{dir_b1574807514940316c988b1142d2b137}{}\doxysection{src/\+Inference Directory Reference}
\label{dir_b1574807514940316c988b1142d2b137}\index{src/Inference Directory Reference@{src/Inference Directory Reference}}
Directory dependency graph for Inference\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{dir_b1574807514940316c988b1142d2b137_dep}
\end{center}
\end{figure}
\doxysubsection*{Directories}
\begin{DoxyCompactItemize}
\item 
directory \mbox{\hyperlink{dir_7f9392eb16bc44ee95df30645ab1e0a8}{M\+C\+MC}}
\item 
directory \mbox{\hyperlink{dir_045ac3f28eba4be8e6ae405066330345}{M\+C\+TS}}
\end{DoxyCompactItemize}
\doxysubsection*{Files}
\begin{DoxyCompactItemize}
\item 
file \mbox{\hyperlink{_batch_8h}{Batch.\+h}}
\item 
file \mbox{\hyperlink{_beam_search_8h}{Beam\+Search.\+h}}
\begin{DoxyCompactList}\small\item\em This is an implementation of beam search that maintains a priority queue of partial states and attempts to find a program with the lowest posterior score. To do this, we choose a node to expand based on its prior plus N\+\_\+\+R\+E\+PS samples of its likelihood, computed by filling in its children at random. This stochastic heuristic is actually inadmissable (in A$\ast$ terms) since it usually overestimates the cost. As a result, it usually makes sense to run at a pretty high temperature, corresponding to a downweighting of the likelihood, and making the heuristic more likely to be admissable. \end{DoxyCompactList}\item 
file \mbox{\hyperlink{_control_8h}{Control.\+h}}
\begin{DoxyCompactList}\small\item\em This class has all the information for running M\+C\+MC or M\+C\+TS in a little package. It defaultly constructs (via \mbox{\hyperlink{struct_control}{Control()}}) to read these from \mbox{\hyperlink{namespace_fleet_args}{Fleet\+Args}}, which are a bunch of variables set by Fleet\+::initialize from the command line. This makes it especially convenient to call with command line arguments, but others can be specified as well. \end{DoxyCompactList}\item 
file \mbox{\hyperlink{_inference_2_enumeration_inference_8h}{Enumeration\+Inference.\+h}}
\begin{DoxyCompactList}\small\item\em Enumeration inferences enumerates hypotheses using a counting algorithm from the grammar. It supports multithreading and requires a hypothesis, grammar, and starting type. \end{DoxyCompactList}\item 
file \mbox{\hyperlink{_hill_climbing_8h}{Hill\+Climbing.\+h}}
\begin{DoxyCompactList}\small\item\em This cute kind of inference keeps a body of N top hypotheses, and successively proposes to them using standard proposals. When it hasn\textquotesingle{}t improved in ctl.\+restart steps, it will restart (resample). Note that this really should use ctl.\+restart$>$0, or else you just climb up one hill. N\+O\+TE\+: We could propose propotional to each hypothesis\textquotesingle{} posterior, but it doesn\textquotesingle{}t matter much because the best gets most probability mass (that\textquotesingle{}s why we don\textquotesingle{}t store more than n=1 defaultly) \end{DoxyCompactList}\item 
file \mbox{\hyperlink{_m_p_i_inference_interface_8h}{M\+P\+I\+Inference\+Interface.\+h}}
\item 
file \mbox{\hyperlink{_prior_inference_8h}{Prior\+Inference.\+h}}
\begin{DoxyCompactList}\small\item\em Inference by sampling from the prior -- doesn\textquotesingle{}t tend to work well, but might be a useful baseline. \end{DoxyCompactList}\item 
file \mbox{\hyperlink{_threaded_inference_interface_8h}{Threaded\+Inference\+Interface.\+h}}
\begin{DoxyCompactList}\small\item\em This manages multiple threads for running inference. This requires a subclass to define run\+\_\+thread, which is what each individual thread should do. All threads can then be called with run(\+Control, Args... args), which copies the control for each thread (setting threads=1) and then passes the args arguments onward. \end{DoxyCompactList}\end{DoxyCompactItemize}
