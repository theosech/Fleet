\doxysection{File List}
Here is a list of all files with brief descriptions\+:\begin{DoxyCompactList}
\item\contentsline{section}{\mbox{\hyperlink{main_8cpp}{main.\+cpp}} }{\pageref{main_8cpp}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_base_node_8h}{Base\+Node.\+h}} \\*This is a general tree class, which we are adding because there are currently at least 3 different tree classes used in different parts of fleet (Nodes, M\+C\+TS, data for Binding\+Theory, etc.). This is an attempt to make a big superclass that puts all of this functionality in one place. It attempts to keep the node size small so that we can use this efficiently in M\+C\+TS in particular }{\pageref{_base_node_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_combinators_8h}{Combinators.\+h}} \\*A grammar for SK combinatory logic. N\+O\+TE\+: Custom\+Ops must be defined here }{\pageref{_combinators_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_errors_8h}{Errors.\+h}} }{\pageref{_errors_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_fleet_8h}{Fleet.\+h}} }{\pageref{_fleet_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_fleet_args_8h}{Fleet\+Args.\+h}} }{\pageref{_fleet_args_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_i_o_8h}{I\+O.\+h}} }{\pageref{_i_o_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_miscellaneous_8h}{Miscellaneous.\+h}} }{\pageref{_miscellaneous_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_m_p_i_8h}{M\+P\+I.\+h}} }{\pageref{_m_p_i_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_numerics_8h}{Numerics.\+h}} }{\pageref{_numerics_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_random_8h}{Random.\+h}} \\*This is a thread\+\_\+local rng that is seeded on construction so that each thread can get a different seed. (Because this seeding is in a constructor, it will be called before rl\+Rng is used) If we just make a thread\+\_\+local variable, it is not seeded well. Note that if we specify random\+\_\+seed it only applies to the first thread (and you get a warning for other threads) }{\pageref{_random_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_singleton_8h}{Singleton.\+h}} }{\pageref{_singleton_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_strings_8h}{Strings.\+h}} }{\pageref{_strings_8h}}{}
\item\contentsline{section}{src/\mbox{\hyperlink{_timing_8h}{Timing.\+h}} }{\pageref{_timing_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_concurrent_queue_8h}{Concurrent\+Queue.\+h}} \\*A concurrent queue class that allows multiple threads to push and consume. Note that this has a fixed, finite size (n) and when its full, we\textquotesingle{}ll block. This prevents us from eating up too much memory }{\pageref{_concurrent_queue_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_discrete_distribution_8h}{Discrete\+Distribution.\+h}} \\*This stores a distribution from values of T to log probabilities. It is used as the return value from calls with randomness }{\pageref{_discrete_distribution_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_integerized_stack_8h}{Integerized\+Stack.\+h}} }{\pageref{_integerized_stack_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_reserved_vector_8h}{Reserved\+Vector.\+h}} }{\pageref{_reserved_vector_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_stack_8h}{Stack.\+h}} \\*Many things in Fleet are stacks and this is designed to allow for rapid changse to the stack type in order to improve speed. std\+::stack appears to be slow. Using vector with some wrappers is faster. Also, vector is great because it allows us to reference the top }{\pageref{_stack_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_top_n_8h}{Top\+N.\+h}} }{\pageref{_top_n_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_vector2_d_8h}{Vector2\+D.\+h}} }{\pageref{_vector2_d_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_vector3_d_8h}{Vector3\+D.\+h}} }{\pageref{_vector3_d_8h}}{}
\item\contentsline{section}{src/\+Containers/\mbox{\hyperlink{_vectors_8h}{Vectors.\+h}} }{\pageref{_vectors_8h}}{}
\item\contentsline{section}{src/\+Data/\mbox{\hyperlink{_datum_8h}{Datum.\+h}} \\*A datum is the default data point for likelihoods, consisting of an input and output type. The reliability is measures the reliability of the data (sometimes number of effective data points, sometimes its the noise in the likelihood }{\pageref{_datum_8h}}{}
\item\contentsline{section}{src/\+Data/\mbox{\hyperlink{_human_datum_8h}{Human\+Datum.\+h}} }{\pageref{_human_datum_8h}}{}
\item\contentsline{section}{src/\+Data/\mbox{\hyperlink{_object_8h}{Object.\+h}} }{\pageref{_object_8h}}{}
\item\contentsline{section}{src/\+Data/\mbox{\hyperlink{_shape_color_size_object_8h}{Shape\+Color\+Size\+Object.\+h}} \\*This object is used in F\+OL and the set function experiments -- just a handy function with a few convenient features }{\pageref{_shape_color_size_object_8h}}{}
\item\contentsline{section}{src/\+Grammar/\mbox{\hyperlink{_grammar_8h}{Grammar.\+h}} \\*A grammar stores all of the rules associated with any kind of nonterminal and permits us to sample as well as compute log probabilities }{\pageref{_grammar_8h}}{}
\item\contentsline{section}{src/\+Grammar/\mbox{\hyperlink{_node_8h}{Node.\+h}} \\*A \mbox{\hyperlink{class_node}{Node}} is the primary internal representation for a program -- it recursively stores a rule and the arguments to a rule. Nodes are generated by grammars and the main thing contained in a \mbox{\hyperlink{class_l_o_t_hypothesis}{L\+O\+T\+Hypothesis}} }{\pageref{_node_8h}}{}
\item\contentsline{section}{src/\+Grammar/\mbox{\hyperlink{_nonterminal_8h}{Nonterminal.\+h}} }{\pageref{_nonterminal_8h}}{}
\item\contentsline{section}{src/\+Grammar/\mbox{\hyperlink{_rule_8h}{Rule.\+h}} \\*A \mbox{\hyperlink{class_rule}{Rule}} stores one possible expansion in the grammar, specifying a nonterminal type, an instruction that gets executed, a forma string, a number of children, and an array of types of each child. Here we \char`\"{}emulate\char`\"{} a type system using t\+\_\+nonterminal to store an integer for the types. $\ast$ }{\pageref{_rule_8h}}{}
\item\contentsline{section}{src/\+Grammar/\+Enumeration/\mbox{\hyperlink{_basic_enumeration_8h}{Basic\+Enumeration.\+h}} }{\pageref{_basic_enumeration_8h}}{}
\item\contentsline{section}{src/\+Grammar/\+Enumeration/\mbox{\hyperlink{_grammar_2_enumeration_2_enumeration_inference_8h}{Enumeration\+Inference.\+h}} }{\pageref{_grammar_2_enumeration_2_enumeration_inference_8h}}{}
\item\contentsline{section}{src/\+Grammar/\+Enumeration/\mbox{\hyperlink{_full_l_z_enumeration_8h}{Full\+L\+Z\+Enumeration.\+h}} \\*Enumerate where we may interpret low numbers as pointers back to C\+O\+M\+P\+L\+E\+TE subtrees. Note that this enumeration will not be unique since different trees will have multiple derivations }{\pageref{_full_l_z_enumeration_8h}}{}
\item\contentsline{section}{src/\+Grammar/\+Enumeration/\mbox{\hyperlink{_partial_l_z_enumeration_8h}{Partial\+L\+Z\+Enumeration.\+h}} \\*Same as \mbox{\hyperlink{class_full_l_z_enumeration}{Full\+L\+Z\+Enumeration}} except that the pointers to previous trees are to {\itshape partial} trees, not full ones }{\pageref{_partial_l_z_enumeration_8h}}{}
\item\contentsline{section}{src/\+Grammar/\+Enumeration/\mbox{\hyperlink{_subtree_enumeration_8h}{Subtree\+Enumeration.\+h}} \\*Enumerate subtrees of a given tree }{\pageref{_subtree_enumeration_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_cached_call_hypothesis_8h}{Cached\+Call\+Hypothesis.\+h}} \\*This is a hypothesis that allows you to cache an entire call on data. N\+O\+TE\+: This only catches std\+::exception, which is not good news }{\pageref{_cached_call_hypothesis_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_grammar_hypothesis_8h}{Grammar\+Hypothesis.\+h}} \\*This stores the human data, as a list of data to condition on data\mbox{[}0\+:ndata\mbox{]}, the data you predict on, and then correct/total counts We defaultly use the H\+YP\textquotesingle{}s output, datum, and data types, but this allows us to specify something different if that\textquotesingle{}s more convenient }{\pageref{_grammar_hypothesis_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_lexicon_8h}{Lexicon.\+h}} \\*A lexicon stores an association of numbers (in a vector) to some other kind of hypotheses (typically a \mbox{\hyperlink{class_l_o_t_hypothesis}{L\+O\+T\+Hypothesis}}). Each of these components is called a \char`\"{}factor.\char`\"{} }{\pageref{_lexicon_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_l_o_t_hypothesis_8h}{L\+O\+T\+Hypothesis.\+h}} \\*A \mbox{\hyperlink{class_l_o_t_hypothesis}{L\+O\+T\+Hypothesis}} is the basic unit for doing L\+OT models. It store a \mbox{\hyperlink{class_node}{Node}} as its value, and handles all of the proposing and computing priors, likelihoods, etc. It compiles this \mbox{\hyperlink{class_node}{Node}} into a \char`\"{}program\char`\"{} which is used to make function calls, which means that the value should only be changed via \mbox{\hyperlink{class_l_o_t_hypothesis_af4c0128f8fd37bb8a02418e2f58c2bc0}{L\+O\+T\+Hypothesis\+::set\+\_\+value}} }{\pageref{_l_o_t_hypothesis_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_proposers_8h}{Proposers.\+h}} }{\pageref{_proposers_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_t_normal_variable_8h}{T\+Normal\+Variable.\+h}} }{\pageref{_t_normal_variable_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_vector_half_normal_hypothesis_8h}{Vector\+Half\+Normal\+Hypothesis.\+h}} }{\pageref{_vector_half_normal_hypothesis_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\mbox{\hyperlink{_vector_normal_hypothesis_8h}{Vector\+Normal\+Hypothesis.\+h}} \\*A \mbox{\hyperlink{class_t_normal_variable}{T\+Normal\+Variable}} encapsulates M\+C\+MC operations on a single real number with a standard normal prior. This is useful for variables in e.\+g. Grammar\+Inference. This has a normal prior on a parameter and then allows an output transformation, which is cached for speed }{\pageref{_vector_normal_hypothesis_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\+Interfaces/\mbox{\hyperlink{_bayesable_8h}{Bayesable.\+h}} \\*The \mbox{\hyperlink{class_bayesable}{Bayesable}} class provides an interface for hypotheses that support Bayesian inference (e.\+g. computing priors, likelihoods, and posteriors) Note that this class stores prior, likelihood, posterior always at temperature 1.\+0, and you can get the values of the posterior at other temperatures via Bayesable.\+at\+\_\+temperature(double t) }{\pageref{_bayesable_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\+Interfaces/\mbox{\hyperlink{_m_c_m_cable_8h}{M\+C\+M\+Cable.\+h}} \\*A class is \mbox{\hyperlink{class_m_c_m_cable}{M\+C\+M\+Cable}} if it is \mbox{\hyperlink{class_bayesable}{Bayesable}} and lets us propose, restart, and check equality (which M\+C\+MC does for speed) }{\pageref{_m_c_m_cable_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\+Interfaces/\mbox{\hyperlink{_searchable_8h}{Searchable.\+h}} \\*A class is searchable if permits us to enumerate and make its neighbors. This class is used by M\+C\+TS and allows us to incrementally search a hypothesis }{\pageref{_searchable_8h}}{}
\item\contentsline{section}{src/\+Hypotheses/\+Interfaces/\mbox{\hyperlink{_serializable_8h}{Serializable.\+h}} }{\pageref{_serializable_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_batch_8h}{Batch.\+h}} }{\pageref{_batch_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_beam_search_8h}{Beam\+Search.\+h}} \\*This is an implementation of beam search that maintains a priority queue of partial states and attempts to find a program with the lowest posterior score. To do this, we choose a node to expand based on its prior plus N\+\_\+\+R\+E\+PS samples of its likelihood, computed by filling in its children at random. This stochastic heuristic is actually inadmissable (in A$\ast$ terms) since it usually overestimates the cost. As a result, it usually makes sense to run at a pretty high temperature, corresponding to a downweighting of the likelihood, and making the heuristic more likely to be admissable }{\pageref{_beam_search_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_control_8h}{Control.\+h}} \\*This class has all the information for running M\+C\+MC or M\+C\+TS in a little package. It defaultly constructs (via \mbox{\hyperlink{struct_control}{Control()}}) to read these from \mbox{\hyperlink{namespace_fleet_args}{Fleet\+Args}}, which are a bunch of variables set by Fleet\+::initialize from the command line. This makes it especially convenient to call with command line arguments, but others can be specified as well }{\pageref{_control_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_inference_2_enumeration_inference_8h}{Enumeration\+Inference.\+h}} \\*Enumeration inferences enumerates hypotheses using a counting algorithm from the grammar. It supports multithreading and requires a hypothesis, grammar, and starting type }{\pageref{_inference_2_enumeration_inference_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_hill_climbing_8h}{Hill\+Climbing.\+h}} \\*This cute kind of inference keeps a body of N top hypotheses, and successively proposes to them using standard proposals. When it hasn\textquotesingle{}t improved in ctl.\+restart steps, it will restart (resample). Note that this really should use ctl.\+restart$>$0, or else you just climb up one hill. N\+O\+TE\+: We could propose propotional to each hypothesis\textquotesingle{} posterior, but it doesn\textquotesingle{}t matter much because the best gets most probability mass (that\textquotesingle{}s why we don\textquotesingle{}t store more than n=1 defaultly) }{\pageref{_hill_climbing_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_m_p_i_inference_interface_8h}{M\+P\+I\+Inference\+Interface.\+h}} }{\pageref{_m_p_i_inference_interface_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_prior_inference_8h}{Prior\+Inference.\+h}} \\*Inference by sampling from the prior -- doesn\textquotesingle{}t tend to work well, but might be a useful baseline }{\pageref{_prior_inference_8h}}{}
\item\contentsline{section}{src/\+Inference/\mbox{\hyperlink{_threaded_inference_interface_8h}{Threaded\+Inference\+Interface.\+h}} \\*This manages multiple threads for running inference. This requires a subclass to define run\+\_\+thread, which is what each individual thread should do. All threads can then be called with run(\+Control, Args... args), which copies the control for each thread (setting threads=1) and then passes the args arguments onward }{\pageref{_threaded_inference_interface_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+M\+C/\mbox{\hyperlink{_chain_pool_8h}{Chain\+Pool.\+h}} \\*A \mbox{\hyperlink{class_chain_pool}{Chain\+Pool}} stores a bunch of M\+C\+M\+C\+Chains and allows you to run them serially or in parallel. N\+O\+TE\+: When you use a \mbox{\hyperlink{class_chain_pool}{Chain\+Pool}}, the results will not be reproducible with seed because timing determines when you switch chains }{\pageref{_chain_pool_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+M\+C/\mbox{\hyperlink{_m_c_m_c_chain_8h}{M\+C\+M\+C\+Chain.\+h}} \\*This represents an M\+C\+MC hain on a hypothesis of type H\+YP. It uses H\+Y\+P\+::propose and H\+Y\+P\+::compute\+\_\+posterior to implement Metropolic\+Hastings }{\pageref{_m_c_m_c_chain_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+M\+C/\mbox{\hyperlink{_parallel_tempering_8h}{Parallel\+Tempering.\+h}} \\*This is a chain pool that runs multiple chains on a ladder of different temperatures and adjusts temperatures in order to balances swaps up and down the ladder (which makes it efficient). The adaptation scheme follows \href{https://arxiv.org/abs/1501.05823}{\texttt{ https\+://arxiv.\+org/abs/1501.\+05823}} N\+O\+TE This starts two extra threads, one for adapting and one for swapping, but they mostly wait around }{\pageref{_parallel_tempering_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+M\+C/\mbox{\hyperlink{_partition_m_c_m_c_8h}{Partition\+M\+C\+M\+C.\+h}} \\*This takes a grammar and expands to a given depth, and then runs a separate M\+C\+MC chain in each partial subtree that is generated }{\pageref{_partition_m_c_m_c_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+T\+S/\mbox{\hyperlink{_full_m_c_t_s_node_8h}{Full\+M\+C\+T\+S\+Node.\+h}} }{\pageref{_full_m_c_t_s_node_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+T\+S/\mbox{\hyperlink{_m_c_t_s_base_8h}{M\+C\+T\+S\+Base.\+h}} }{\pageref{_m_c_t_s_base_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+T\+S/\mbox{\hyperlink{_minimal_m_c_t_s_node_8h}{Minimal\+M\+C\+T\+S\+Node.\+h}} }{\pageref{_minimal_m_c_t_s_node_8h}}{}
\item\contentsline{section}{src/\+Inference/\+M\+C\+T\+S/\mbox{\hyperlink{_partial_m_c_t_s_node_8h}{Partial\+M\+C\+T\+S\+Node.\+h}} }{\pageref{_partial_m_c_t_s_node_8h}}{}
\item\contentsline{section}{src/\+Statistics/\mbox{\hyperlink{_finite_history_8h}{Finite\+History.\+h}} \\*A \mbox{\hyperlink{class_finite_history}{Finite\+History}} stores the previous N examples of something of type T. This is used e.\+g. in M\+C\+MC in order to count the acceptance ratio on the previous N samples }{\pageref{_finite_history_8h}}{}
\item\contentsline{section}{src/\+Statistics/\mbox{\hyperlink{_fleet_statistics_8h}{Fleet\+Statistics.\+h}} }{\pageref{_fleet_statistics_8h}}{}
\item\contentsline{section}{src/\+Statistics/\mbox{\hyperlink{_median_f_a_m_e_8h}{Median\+F\+A\+M\+E.\+h}} \\*A streaming median class implementing the F\+A\+ME algorithm Here, we initialize both the step size and M with the current sample \href{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.7376&rep=rep1&type=pdf}{\texttt{ http\+://citeseerx.\+ist.\+psu.\+edu/viewdoc/download?doi=10.\+1.\+1.\+108.\+7376\&rep=rep1\&type=pdf}} }{\pageref{_median_f_a_m_e_8h}}{}
\item\contentsline{section}{src/\+Statistics/\mbox{\hyperlink{_reservoir_sample_8h}{Reservoir\+Sample.\+h}} \\*A reservoir sampling algorithm. N\+O\+TE\+: This was simplified from an old version that permitted unequal weights among elements. We may go back to that eventually -\/ \href{https://en.wikipedia.org/wiki/Reservoir_sampling\#Weighted_random_sampling_}{\texttt{ https\+://en.\+wikipedia.\+org/wiki/\+Reservoir\+\_\+sampling\#\+Weighted\+\_\+random\+\_\+sampling\+\_\+}} }{\pageref{_reservoir_sample_8h}}{}
\item\contentsline{section}{src/\+Statistics/\mbox{\hyperlink{_streaming_statistics_8h}{Streaming\+Statistics.\+h}} \\*A class to store a bunch of statistics about incoming data points, including min, max, mean, etc }{\pageref{_streaming_statistics_8h}}{}
\item\contentsline{section}{src/\+Threads/\mbox{\hyperlink{_coroutines_8h}{Coroutines.\+h}} \\*This little object will return true once every n times it is converted to a bool }{\pageref{_coroutines_8h}}{}
\item\contentsline{section}{src/\+Threads/\mbox{\hyperlink{_ordered_lock_8h}{Ordered\+Lock.\+h}} \\*A F\+I\+FO mutex (from stackoverflow) \href{https://stackoverflow.com/questions/14792016/creating-a-lock-that-preserves-the-order-of-locking-attempts-in-c11}{\texttt{ https\+://stackoverflow.\+com/questions/14792016/creating-\/a-\/lock-\/that-\/preserves-\/the-\/order-\/of-\/locking-\/attempts-\/in-\/c11}} }{\pageref{_ordered_lock_8h}}{}
\item\contentsline{section}{src/\+Threads/\mbox{\hyperlink{_spin_lock_8h}{Spin\+Lock.\+h}} }{\pageref{_spin_lock_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\mbox{\hyperlink{_builtins_8h}{Builtins.\+h}} }{\pageref{_builtins_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\mbox{\hyperlink{_runtime_counter_8h}{Runtime\+Counter.\+h}} \\*This class manages counting operations at runtime and interfaces operations to a grammar N\+O\+TE\+: Currently we don\textquotesingle{}t track each arg separately, since that\textquotesingle{}s a pain }{\pageref{_runtime_counter_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\mbox{\hyperlink{_virtual_machine_control_8h}{Virtual\+Machine\+Control.\+h}} }{\pageref{_virtual_machine_control_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\mbox{\hyperlink{_virtual_machine_pool_8h}{Virtual\+Machine\+Pool.\+h}} \\*A little class that any \mbox{\hyperlink{class_virtual_machine_pool}{Virtual\+Machine\+Pool}} A\+ND Virtual\+Machines inherit to control their behavior. N\+O\+TE That this is not passed around like Fleet\+::\+Control--it is just meant to be a place to set static variables And then it is inherited by \mbox{\hyperlink{class_virtual_machine_pool}{Virtual\+Machine\+Pool}} }{\pageref{_virtual_machine_pool_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\mbox{\hyperlink{_virtual_machine_state_8h}{Virtual\+Machine\+State.\+h}} \\*This represents the state of a partial evaluation of a program, corresponding to the value of all of the stacks of various types (which are stored as templates from V\+M\+\_\+\+T\+Y\+P\+ES). ~\newline
 The idea here is that we want to be able to encapsulate everything about the evaluation of a tree so that we can stop it in the middle and resume later, as is required for stochastics. This must be templated because it depends on the types in the grammar. These will typically be stored in a \mbox{\hyperlink{class_virtual_machine_pool}{Virtual\+Machine\+Pool}} and not called directly, unless you know that there are no stochastics }{\pageref{_virtual_machine_state_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\mbox{\hyperlink{_v_m_s_runtime_error_8h}{V\+M\+S\+Runtime\+Error.\+h}} }{\pageref{_v_m_s_runtime_error_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\mbox{\hyperlink{_v_m_status_8h}{V\+M\+Status.\+h}} }{\pageref{_v_m_status_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\+Program/\mbox{\hyperlink{_instruction_8h}{Instruction.\+h}} \\*F here is a point to a void(\+Virtual\+Machine\+State\+\_\+t$\ast$ vms, int arg), where arg is just a supplemental argument, used to pass indices in lexica and jump sizes etc for other primitives }{\pageref{_instruction_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\+Program/\mbox{\hyperlink{_ops_8h}{Ops.\+h}} }{\pageref{_ops_8h}}{}
\item\contentsline{section}{src/\+Virtual\+Machine/\+Program/\mbox{\hyperlink{_program_8h}{Program.\+h}} \\*A program here stores just a stack of instructions which can be executed by the Virtual\+Machine\+State\+\_\+t. We\textquotesingle{}ve optimized the reserve in the constructor to be the fasest }{\pageref{_program_8h}}{}
\item\contentsline{section}{Testing/\+Basics/\mbox{\hyperlink{_basics_2_main_8cpp}{Main.\+cpp}} }{\pageref{_basics_2_main_8cpp}}{}
\item\contentsline{section}{Testing/\+Detailed\+Balance/\mbox{\hyperlink{_detailed_balance_2_main_8cpp}{Main.\+cpp}} }{\pageref{_detailed_balance_2_main_8cpp}}{}
\item\contentsline{section}{Testing/\+Insert\+Delete\+Probability/\mbox{\hyperlink{_insert_delete_probability_2_main_8cpp}{Main.\+cpp}} }{\pageref{_insert_delete_probability_2_main_8cpp}}{}
\end{DoxyCompactList}
