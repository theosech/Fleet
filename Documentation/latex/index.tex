\hypertarget{index_intro_sec}{}\doxysection{Introduction}\label{index_intro_sec}
Fleet is a C++ library for programming language of thought models. In these models, we specify a grammar of primitive operations which can be composed to form complex hypotheses. These hypotheses are best thought of as programs in a (mental) programming language, and the job of learners is to observe data (typically inputs and outputs of programs) and infer the most likely program to have generated the outputs from the inputs. This is accomplished in Fleet by using a fully-\/\+Bayesian setup, with a prior over programs typically defined thought a Probabilistic Context-\/\+Free \mbox{\hyperlink{class_grammar}{Grammar}} (P\+C\+FG) and a likelihood model that typically says that the output of a program is observed with some noise.

Fleet is most similar to L\+O\+Tlib (\href{https://github.com/piantado/LOTlib3}{\texttt{ https\+://github.\+com/piantado/\+L\+O\+Tlib3}}) but is considerably faster. L\+O\+Tlib converts grammar productions into python expressions which are then evaled in python; this process is flexible and powerful, but slow. Fleet avoids this by implementing a lightweight stack-\/based virtual machine in which programs can be directly evaluated. This is especially advantageous when evaluating stochastic hypotheses (e.\+g. those using \mbox{\hyperlink{_random_8h_a40e7e030d95195c87c566b03fdefe44c}{flip()}} or \mbox{\hyperlink{_random_8h_a3585a6278806f57b964ccd1060f3b8ee}{sample()}}) in which multiple execution paths must be evaluated. Fleet stores these multiple execution traces of a single program in a priority queue (sorted by probability) and allows you to rapidly explore the space of execution traces.

Fleet is structured to automatically create this virtual machine and a grammar for programs from just the type specification on primitives\+: a function signature yields a P\+C\+FG because the return type can be thought of as a nonterminal in a P\+C\+FG and its arguments can be thought of as children (right hand side of a P\+C\+FG rule). A P\+C\+FG expanded in this way will yield a correctly-\/typed expression, a program, where each function has arguments of the correct types. Note that in Fleet, these types in the P\+C\+FG must be C++ types (intrinsics, classes, or structs), and two types that are the same are always considered to have the same nonterminal type.

Fleet requires you to define a \mbox{\hyperlink{class_grammar}{Grammar}} which includes {\itshape all} of the nonterminal types that are used anywhere in the grammar. Fleet makes heavy use of template metaprogramming, which prevents you from ever having to explicitly write the grammar itself, but it does implicitly construct a grammar using these operations.

In addition, Fleet has a number of built-\/in operations, which do special things to the virtual machine. These include \mbox{\hyperlink{namespace_builtins_afc5e30bbc3268c0f88d8540421d453ff}{Builtins\+::\+Flip}}, which stores multiple execution traces; \mbox{\hyperlink{namespace_builtins_abadd5f4188def3a49ec73f692460c9a2}{Builtins\+::\+If}} which uses short-\/circuit evaluation; \mbox{\hyperlink{namespace_builtins_a0771c881975000f812bbb41fffcb9fb0}{Builtins\+::\+Recurse}}, which handles recursives hypotheses; and \mbox{\hyperlink{namespace_builtins_a25cc5743603132ee78d118a4ca039c68}{Builtins\+::X}} which provides the argument to the expression.\hypertarget{index_subsec_install}{}\doxysubsection{Installation}\label{index_subsec_install}
Fleet is based on header-\/files, and requires no additional dependencies. Command line arguments are processed in C\+L11.\+hpp, which is included in src/dependencies/.

The easiest way to begin using Fleet is to modify one of the examples. For simple rational-\/rules style inference, try Models/\+Rational\+Rules; for an example using stochastic operations, try Models/\+Formal\+Language\+Theory-\/\+Simple.

Fleet is developed using G\+NU g++ 10 and requires C++-\/20.\hypertarget{index_subsec_examples}{}\doxysubsection{Examples}\label{index_subsec_examples}
Fleet contains several implemented examples of existing program-\/induction models, including identical or close variants of\+:


\begin{DoxyItemize}
\item The rational rules model (Examples/\+Rational\+Rules)\+: Goodman, N. D., Tenenbaum, J. B., Feldman, J., \& Griffiths, T. L. (2008). A rational analysis of rule‚Äêbased concept learning. Cognitive science, 32(1), 108-\/154.
\item The number model (Examples/\+Number-\/\+Simple)\+: Piantadosi, S. T., Tenenbaum, J. B., \& Goodman, N. D. (2012). Bootstrapping in a language of thought\+: A formal model of numerical concept learning. Cognition, 123(2), 199-\/217.
\item The number game (Examples/\+Number\+Game)\+: Tenenbaum, J. B. (1999). A Bayesian framework for concept learning (Doctoral dissertation, Massachusetts Institute of Technology).
\item Inference of a grammar (Examples/\+Grammar\+Inference-\/$\ast$)\+: Piantadosi, S. T., Tenenbaum, J. B., \& Goodman, N. D. (2016). The logical primitives of thought\+: Empirical foundations for compositional cognitive models. Psychological review, 123(4), 392.
\item Formal language theory learning (Examples/\+Formal\+Language\+Theory-\/$\ast$)\+: Yang \& Piantadosi, forthcoming
\end{DoxyItemize}

as well as several other examples, including sorting and first order logical theories.\hypertarget{index_subsec_style}{}\doxysubsection{Style}\label{index_subsec_style}
Fleet is currently written using a signle-\/file, header-\/only style. This allows for rapid refactoring and prototyping since declarations and implementations are not in separate files. This style may change in the future because it also leads to slower compilation times.\hypertarget{index_subsec_inference}{}\doxysubsection{Inference}\label{index_subsec_inference}
Fleet provides a number of simple inference routines to use. Examples of each can be found in Models/\+Sorting


\begin{DoxyItemize}
\item Markov-\/\+Chain Monte-\/\+Carlo
\item M\+C\+MC With Parallel Tempering
\item Monte-\/\+Carlo Tree search
\item Beam search
\item Enumeration (with a fast, fancy implementation)
\end{DoxyItemize}

Generally, we find that \mbox{\hyperlink{class_parallel_tempering}{Parallel\+Tempering}} is the fastest and most effective way to search these spaces of programs. These can be compared in Models/\+Sorting, which has examples of each. ~\newline
\hypertarget{index_tutorial_sec}{}\doxysection{Tutorial}\label{index_tutorial_sec}
To illustrate how Fleet works, let\textquotesingle{}s walk through a simple example\+: the key parts of Formal\+Language\+Theory-\/\+Simple. This is a program induction model which takes a collection of strings and tries to find a stochastic program which can explain the observed strings. For example, it might see data like \{\char`\"{}ab\char`\"{}, \char`\"{}abab\char`\"{}, \char`\"{}ababab\char`\"{}\} and then infer that the language is (ab)$^\wedge$n.

Let\textquotesingle{}s first walk through the grammar definition. Here, we first import \mbox{\hyperlink{_grammar_8h}{Grammar.\+h}} and also \mbox{\hyperlink{_singleton_8h}{Singleton.\+h}}. \mbox{\hyperlink{class_singleton}{Singleton}} is a design pattern that permits only one copy of an object to be constructed, which is used here to ensure that we only have one grammar (and aren\textquotesingle{}t, e.\+g. passing copies of it around). Typical to Fleet\textquotesingle{}s code, we define our own grammar as My\+Grammar. The first two template arguments are the input and output types of the function we are learning (here, strings to strings) and the next two are (variadic) template arguments for all of the nonterminal types used by the grammar (here, strings and bools). The input type determines the type of any arguments to productions in the grammar; the output type determines the type of the root (e.\+g. what evaluating a program generated from this grammar will return).


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{preprocessor}{\#include <string>}}
\DoxyCodeLine{\textcolor{keyword}{using} S = std::string; \textcolor{comment}{// just for convenience}}
\DoxyCodeLine{ }
\DoxyCodeLine{\textcolor{preprocessor}{\#include "\mbox{\hyperlink{_grammar_8h}{Grammar.h}}"}}
\DoxyCodeLine{\textcolor{preprocessor}{\#include "\mbox{\hyperlink{_singleton_8h}{Singleton.h}}"}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keyword}{class }MyGrammar : \textcolor{keyword}{public} \mbox{\hyperlink{class_grammar}{Grammar}}<S,S,  S,bool>,}
\DoxyCodeLine{                  \textcolor{keyword}{public} \mbox{\hyperlink{class_singleton}{Singleton}}<MyGrammar> \{}
\DoxyCodeLine{\textcolor{keyword}{public}:}
\DoxyCodeLine{    MyGrammar() \{}
\DoxyCodeLine{        \textcolor{comment}{// compute the tail of a string: tail(wxyz) -\/> xyz}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"tail(\%s)"},      +[](S s)      -\/> S \{ \textcolor{keywordflow}{return} (s.empty() ? S(\textcolor{stringliteral}{""}) : s.substr(1,S::npos)); \});}
\DoxyCodeLine{}
\DoxyCodeLine{        \textcolor{comment}{// compute the head of a string: tail(wxyz) -\/> w}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"head(\%s)"},      +[](S s)      -\/> S \{ \textcolor{keywordflow}{return} (s.empty() ? S(\textcolor{stringliteral}{""}) : S(1,s.at(0))); \});}
\DoxyCodeLine{}
\DoxyCodeLine{        \textcolor{comment}{// concatenate strings pair(wx,yz) -\/> wxyz}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"pair(\%s,\%s)"},   +[](S a, S b) -\/> S \{ }
\DoxyCodeLine{            \textcolor{keywordflow}{if}(a.length() + b.length() > MAX\_LENGTH) \textcolor{keywordflow}{throw} \mbox{\hyperlink{class_v_m_s_runtime_error}{VMSRuntimeError}}(); \textcolor{comment}{// caught inside VirtualMachineState::run}}
\DoxyCodeLine{            \textcolor{keywordflow}{else}                                     \textcolor{keywordflow}{return} a+b; }
\DoxyCodeLine{        \});}
\DoxyCodeLine{}
\DoxyCodeLine{        \textcolor{comment}{// the empty string}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"\(\backslash\)u00D8"},        +[]()         -\/> S          \{ \textcolor{keywordflow}{return} S(\textcolor{stringliteral}{""}); \});}
\DoxyCodeLine{          }
\DoxyCodeLine{        \textcolor{comment}{// check if two strings are equal}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"(\%s==\%s)"},      +[](S x, S y) -\/> \textcolor{keywordtype}{bool}       \{ \textcolor{keywordflow}{return} x==y; \});}
\DoxyCodeLine{}
\DoxyCodeLine{}
\DoxyCodeLine{        \textcolor{comment}{// logical operations}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"and(\%s,\%s)"},    Builtins::And<MyGrammar>);}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"or(\%s,\%s)"},     Builtins::Or<MyGrammar>);}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"not(\%s)"},       Builtins::Not<MyGrammar>);}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"if(\%s,\%s,\%s)"},  Builtins::If<MyGrammar,S>);}
\DoxyCodeLine{        }
\DoxyCodeLine{        \textcolor{comment}{// access the argument x to the program (defined to a string type above)}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"x"},             Builtins::X<MyGrammar>);}
\DoxyCodeLine{         }
\DoxyCodeLine{        \textcolor{comment}{// random coin flip (this does something fancy in evaluation)}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"flip()"},        Builtins::Flip<MyGrammar>, 10.0);}
\DoxyCodeLine{         }
\DoxyCodeLine{        \textcolor{comment}{// recursion}}
\DoxyCodeLine{        \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{add}}(\textcolor{stringliteral}{"recurse(\%s)"},   Builtins::Recurse<MyGrammar>);}
\DoxyCodeLine{        }
\DoxyCodeLine{        \textcolor{comment}{// add all the characters in our alphabet (alphabet is global variable defined on the command line)}}
\DoxyCodeLine{        \textcolor{keywordflow}{for}(\textcolor{keyword}{const} \textcolor{keywordtype}{char} c : alphabet) \{}
\DoxyCodeLine{            \mbox{\hyperlink{class_grammar_af43a4d8c3c2c7df80a916a5219b7232c}{add\_terminal}}( \mbox{\hyperlink{_strings_8h_a1bb5ec0bee0c8456e3fcc87cc012d055}{Q}}(S(1,c)), S(1,c), 5.0/alphabet.length());}
\DoxyCodeLine{        \}}
\DoxyCodeLine{        }
\DoxyCodeLine{    \}}
\DoxyCodeLine{\} grammar;}
\end{DoxyCode}


Then, in the constructor My\+Grammar(), we call the member function \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{Grammar\+::add}} which takes two arguments\+: a string for how to show the function (called a \char`\"{}format\char`\"{}), and a lambda expression for the function itself. The string formats are just for show -- they have nothing to do with how the program is evaluated and expressions in these strings are never interpreted as code. Each string format uses \char`\"{}\%s\char`\"{} to denote the string of its children. So, when Fleet is asked to display a program, it recursively substitutes into these format strings. Fleet checks for you that you have as many \char`\"{}\%s\char`\"{}es as you have arguments to each function and will complain if it\textquotesingle{}s wrong. (N\+O\+TE\+: if you need to display children in a different ordered sequence, Fleet also supports this via \char`\"{}\%1\char`\"{}, \char`\"{}\%2\char`\"{}, etc.).

The second argument to \mbox{\hyperlink{class_grammar_a07ae62095abaf00b3da2fc5065c941bf}{Grammar\+::add}} is a lambda expression which computes and returns the value of each function (e.\+g. for \char`\"{}tail(\%s)\char`\"{} it compute the tail of a string -- everything except the first character. Note that this function, as is generally the case in Fleet, attempts to be relatively fault-\/tolerant rather than throwing exceptions because that\textquotesingle{}s faster. In this case, we just define the tail of an empty string to be the empty string, rather than an error.

The functions for computing the head of a string is defined similarly. The \char`\"{}pair(\%s,\%s)\char`\"{} function is meant to concatenate strings but it actually needs to do a little checking because otherwise it\textquotesingle{}s very easy to write programs which create exponentially long strings. So this function checks if its two argument lengths are above a global variable M\+A\+X\+\_\+\+L\+E\+N\+G\+TH and if so it throws a \mbox{\hyperlink{class_v_m_s_runtime_error}{V\+M\+S\+Runtime\+Error}} (\mbox{\hyperlink{class_virtual_machine_state}{Virtual\+Machine\+State}} error) which is caught and handled internally in Fleet. (Note that in the actual Model code, there is a more complex version of pair which is a bit faster, as it modifies strings stored in the \mbox{\hyperlink{class_virtual_machine_state}{Virtual\+Machine\+State}} stack rather than passing them around, as here).

Then, we have a function which takes no arguments and only returns the empty string. Here, we have given it a Unicode name \textbackslash{}u00\+D8 which will appear/render in most terminals as epsilon (a convention for the empty string in formal language theory).

The \char`\"{}(\%s==\%s)\char`\"{} function computes whether two strings are equal and returns a bool. Note that generally it is helpful to enclose expressions like this in parentheses (i.\+e. \char`\"{}(...)\char`\"{}) because without this, the printed programs can be ambiguous.

Note that in each of these lambda expressions, the input types (e.\+g. \char`\"{}\+S a, S b\char`\"{} in \char`\"{}pair\char`\"{}) and return type (S) really matter. Fleet uses some fancy template magic to extract these types from the functions themselves and build the required grammar. That allows it to start with My\+Grammar\textquotesingle{}s return type and sample a composition of functions which yield this type.

My\+Grammar also adds built-\/in logical operations. \mbox{\hyperlink{namespace_builtins}{Builtins}} are functions that we do {\itshape not} define ourselves using lambdas. We certainly could, but these are buitlin because they are a bit fancier than what you might think. Specifically, in most computer science applications we want the versions of these functions which involve \href{https://en.wikipedia.org/wiki/Short-circuit_evaluation}{\texttt{ short circuit evaluation}}. For example, and(x,y) won\textquotesingle{}t evaluate y if x is false, which for us ends up with a measurably faster implementation. This is maybe most important though for \char`\"{}if(\%s,\%s,\%s)\char`\"{}, where we only want to evaluate one branch, depending on which way the boolean comes out. The implementation of correct short-\/circuit evaluation depends on some of the internals of Fleet and so it\textquotesingle{}s best to use the built-\/in versions of these functions.

We also have a special fucntion \mbox{\hyperlink{namespace_builtins_a25cc5743603132ee78d118a4ca039c68}{Builtins\+::X}} which provides the argument to the function/program we are learning. We defaulty give this the name \char`\"{}x\char`\"{}.

The \char`\"{}flip()\char`\"{} primitive is somewhat fancy (and Buillt-\/in) because it is a stochastic operation, which acts like a coin flip, returning true half of the time and false half of the time (Fleet also a built-\/in biased coin, which takes a coin weight as a parameter). This is fancy because it means that when the program evaluates, there is no longer one single output, but rather a distribution of possible return values. Fleet will hand these back to you as a \mbox{\hyperlink{class_discrete_distribution}{Discrete\+Distribution}} of the output type of the function. Here, we have included 10.\+0 after the \mbox{\hyperlink{namespace_builtins_afc5e30bbc3268c0f88d8540421d453ff}{Builtins\+::\+Flip}}. This is an optional number which can be included for any primitive and it determines the probability in the P\+C\+FG of each each expansion (they are summed and renormalized for each nonterminal type). In this case, we need to upweight the probability of Flip in order to make a proper P\+C\+FG (e.\+g. one where no probabliity is given to infinite trees) because otherwise the and,or,not operatiosn above will lead to infinite trees. The default weight for all operations (when its not specified) is 1.\+0, meaning that 10.\+0 makes it ten times as likely that a bool will expand to a flip than the others. In general, you will want to upweight the terminal rules (those with no children) in order to keep grammars proper.

The next operation is \mbox{\hyperlink{namespace_builtins_a0771c881975000f812bbb41fffcb9fb0}{Builtins\+::\+Recurse}}, which allows a defined function to call itself recursively. This is a special \mbox{\hyperlink{struct_builtin}{Builtin}} because it requires us to evaluate the entire program in which it occurs again, and use the output of that program. Note that in general as we search over programs, we will find things that recurse infinitely -- Fleet\textquotesingle{}s \mbox{\hyperlink{class_virtual_machine_state}{Virtual\+Machine\+State}} keeps track of how many recursive calls a single program has made (via \mbox{\hyperlink{class_virtual_machine_state_aa35593f67d1ea4e838fec8e7a8d33897}{Virtual\+Machine\+State\+::recursion\+\_\+depth}}) and when it exceeds \mbox{\hyperlink{struct_virtual_machine_control_a486795b8d9b8aab1d62840da25ae91be}{Virtual\+Machine\+Control\+::\+M\+A\+X\+\_\+\+R\+E\+C\+U\+R\+SE}} or when the total runtime exceeds \mbox{\hyperlink{struct_virtual_machine_control_a963c0a16ad95a4723255b4ce6eafb113}{Virtual\+Machine\+Control\+::\+M\+A\+X\+\_\+\+R\+U\+N\+\_\+\+P\+R\+O\+G\+R\+AM}}, Fleet will halt evaluation of the program.

Finally, this grammar adds one terminal rule for each character in the global string \char`\"{}alphabet.\char`\"{} Here, these characters are converted to strings containing a single character because char is not a nonterminal type in the grammar we defined. The entire collection of characters is given an unnonormalized grammar probabiltiy of 5.\+0.

Next, we define a class, My\+Hypothesis, which defines the program hypotheses we are going to be learning. The simplest form for this is to use something of type \mbox{\hyperlink{class_l_o_t_hypothesis}{L\+O\+T\+Hypothesis}}, which defines built-\/in functions for computing the prior, copying, proposing, etc. 
\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{preprocessor}{\#include "\mbox{\hyperlink{_l_o_t_hypothesis_8h}{LOTHypothesis.h}}"}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Declare a hypothesis class}}
\DoxyCodeLine{\textcolor{keyword}{class }MyHypothesis : \textcolor{keyword}{public} \mbox{\hyperlink{class_l_o_t_hypothesis}{LOTHypothesis}}<MyHypothesis,S,S,MyGrammar,\&grammar> \{}
\DoxyCodeLine{\textcolor{keyword}{public}:}
\DoxyCodeLine{    \textcolor{keyword}{using} Super =  \mbox{\hyperlink{class_l_o_t_hypothesis}{LOTHypothesis<MyHypothesis,S,S,MyGrammar>}};}
\DoxyCodeLine{    \textcolor{keyword}{using} Super::Super; \textcolor{comment}{// inherit the constructors}}
\DoxyCodeLine{    }
\DoxyCodeLine{    \textcolor{keywordtype}{double} \mbox{\hyperlink{class_l_o_t_hypothesis_a020bfe8e12d80add92c665518650c4cb}{compute\_single\_likelihood}}(\textcolor{keyword}{const} datum\_t\& x)\textcolor{keyword}{ override }\{   }
\DoxyCodeLine{     }
\DoxyCodeLine{        \textcolor{comment}{// MyHypothesis stores a program, and "call" will call it with a given input}}
\DoxyCodeLine{        \textcolor{comment}{// The output is a DiscreteDistribution on all of the outputs of that program}}
\DoxyCodeLine{        \textcolor{keyword}{const} \textcolor{keyword}{auto} out = \mbox{\hyperlink{class_l_o_t_hypothesis_a625f5094ee8f59e8ada3a7bf5a6dd68f}{call}}(x.input, \textcolor{stringliteral}{""}); }
\DoxyCodeLine{          }
\DoxyCodeLine{        \textcolor{comment}{// we need this to compute the likelihood}}
\DoxyCodeLine{        \textcolor{keyword}{const} \textcolor{keyword}{auto} log\_A = log(alphabet.size());}
\DoxyCodeLine{        }
\DoxyCodeLine{        \textcolor{comment}{// Likelihood comes from all of the ways that we can delete from the end and the append to make the observed output. }}
\DoxyCodeLine{        \textcolor{comment}{// So this requires us to sum over all of the output values, for a single data point. }}
\DoxyCodeLine{        \textcolor{keywordtype}{double} lp = -\/\mbox{\hyperlink{_numerics_8h_af9434aea82baf2f6a5d9b6f9e36db08e}{infinity}};}
\DoxyCodeLine{        \textcolor{keywordflow}{for}(\textcolor{keyword}{auto}\& o : out.values()) \{ \textcolor{comment}{// add up the probability from all of the strings}}
\DoxyCodeLine{            lp = \mbox{\hyperlink{_numerics_8h_a558a1133b9942f8debd559bb9317bca3}{logplusexp}}(lp, o.second + p\_delete\_append<strgamma,strgamma>(o.first, x.output, log\_A));}
\DoxyCodeLine{        \}}
\DoxyCodeLine{        \textcolor{keywordflow}{return} lp;}
\DoxyCodeLine{    \}}
\DoxyCodeLine{    }
\DoxyCodeLine{    \textcolor{keywordtype}{void} \mbox{\hyperlink{class_bayesable_a87d5d9481d6a72b017e44b175071fa5e}{print}}(std::string prefix=\textcolor{stringliteral}{""})\textcolor{keyword}{ override }\{}
\DoxyCodeLine{        \textcolor{comment}{// Override the default "print" function by prepending on a view of the distribution }}
\DoxyCodeLine{        \textcolor{comment}{// that was output (Fleet normally would just show the program)}}
\DoxyCodeLine{        prefix = prefix+\textcolor{stringliteral}{"\#\(\backslash\)n\#"} +  this-\/>\mbox{\hyperlink{class_l_o_t_hypothesis_a625f5094ee8f59e8ada3a7bf5a6dd68f}{call}}(\textcolor{stringliteral}{""}, \textcolor{stringliteral}{"<err>"}).string() + \textcolor{stringliteral}{"\(\backslash\)n"};}
\DoxyCodeLine{        \mbox{\hyperlink{namespace_fleet_args_acf2f80bb2810cea3b3eeef0c4b0edf03}{Super::print}}(prefix); }
\DoxyCodeLine{    \}}
\DoxyCodeLine{\};  }
\end{DoxyCode}


Here, My\+Hypothesis uses the \href{https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern}{\texttt{ curiously recurring template pattern}} to pass itself, so that it knows how to make copies of itself. The other template arguments are the input and output types of its function (string to string) and the \mbox{\hyperlink{class_grammar}{Grammar}} type it uses (My\+Grammar). The address of the grammar itself \&grammar is also part of the type. Then, we inherit \mbox{\hyperlink{class_l_o_t_hypothesis}{L\+O\+T\+Hypothesis}}\textquotesingle{} constructors (via Super\+::\+Super\textquotesingle{}s \href{https://en.wikipedia.org/wiki/C\%2B\%2B11\#Object_construction_improvement}{\texttt{ insanity}} in C++).

Primarily, what we have to define here is the compute\+\_\+single\+\_\+likelihood function, which defines the likelihood of a single observed data string. To compute this, we first call the function (\mbox{\hyperlink{class_l_o_t_hypothesis_a625f5094ee8f59e8ada3a7bf5a6dd68f}{L\+O\+T\+Hypothesis\+::call}}) on the observed input. This returns a Discrete\+Distribution$<$std\+::string$>$ of outputs. Note that the outputs which return errors are mapped to the second argument to call, in this case the empty string. Then, we loop over outputs and add up the likelihood of the observed output x.\+ouput given the program output o.\+first weighted by the program\textquotesingle{}s probability of that output o.\+second. This part uses p\+\_\+delete\+\_\+append, which is a string edit likelihood that assigns nonzero probability of any string being corrupted to any other. It computes this by imagining that the output string was corrupted by noise that deleted from the end of the string, and then appended, where both operations take place with geometric probabilities. These probabilities are passed as template arguments since that lets us compute some key pieces of this at compile time, yielding much faster code (this is a hot part of any string-\/based inference model).

We also define a print function which allows us to say how we print out the program hypothesis. Defaultly, any \mbox{\hyperlink{class_l_o_t_hypothesis}{L\+O\+T\+Hypothesis}} will just print (using the format strings like \char`\"{}pair(\%s,\%s)\char`\"{} above) but here we would like to also show the distribution of outputs when we print, so this prints a line with a \mbox{\hyperlink{class_l_o_t_hypothesis_a625f5094ee8f59e8ada3a7bf5a6dd68f}{L\+O\+T\+Hypothesis\+::call}} (which is a \mbox{\hyperlink{class_discrete_distribution}{Discrete\+Distribution}}) and then a .string() call on the returned value.

The last piece of code is the actual running\+: Here, we define a Fleet object, which basically manages the input/output. We tell it that we want to be able to specify the alphabet and a string for the data (comma separated strings) on the command line. We create a grammar and note that this must happend after Fleet.\+initialize, since creating the grammar object needs to know the alphabet. Then, we create a \mbox{\hyperlink{class_top_n}{TopN}} object to store the top hypotheses we have found. This is basically a sorted collection of the best hypotheses found so far. We set a few control aspects of our Virtual\+Machine (e.\+g. how many steps we should run each program for, how many outputs we will consider for each program). We convert our datastr (specified on the command line) to type My\+Hypothesis\+::data\+\_\+t, and do a check on whether the data contains anything not in the alphabet.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{preprocessor}{\#include "Top.h"}}
\DoxyCodeLine{\textcolor{preprocessor}{\#include "\mbox{\hyperlink{_parallel_tempering_8h}{ParallelTempering.h}}"}}
\DoxyCodeLine{\textcolor{preprocessor}{\#include "\mbox{\hyperlink{_fleet_8h}{Fleet.h}}"} }
\DoxyCodeLine{\textcolor{preprocessor}{\#include "\mbox{\hyperlink{_builtins_8h}{Builtins.h}}"}}
\DoxyCodeLine{\textcolor{preprocessor}{\#include "\mbox{\hyperlink{_v_m_s_runtime_error_8h}{VMSRuntimeError.h}}"}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// define this so we can use it}}
\DoxyCodeLine{std::string alphabet = \textcolor{stringliteral}{"abcd"};}
\DoxyCodeLine{  }
\DoxyCodeLine{std::string datastr = \textcolor{stringliteral}{"a:aabb,c:ccbb"}; \textcolor{comment}{// input-\/output pairs in our observed data}}
\DoxyCodeLine{ }
\DoxyCodeLine{\textcolor{keywordtype}{int} \mbox{\hyperlink{main_8cpp_a3c04138a5bfe5d72780bb7e82a18e627}{main}}(\textcolor{keywordtype}{int} argc, \textcolor{keywordtype}{char}** argv)\{ }
\DoxyCodeLine{    }
\DoxyCodeLine{    \textcolor{comment}{// define a Fleet object}}
\DoxyCodeLine{    Fleet fleet(\textcolor{stringliteral}{"A simple, one-\/factor formal language learner"});}
\DoxyCodeLine{    fleet.add\_option(\textcolor{stringliteral}{"-\/a,-\/-\/alphabet"}, alphabet, \textcolor{stringliteral}{"Alphabet we will use"});    \textcolor{comment}{// add my own args}}
\DoxyCodeLine{    fleet.add\_option(\textcolor{stringliteral}{"-\/d,-\/-\/data"},     datastr, \textcolor{stringliteral}{"Comma separated list of input data strings"});   }
\DoxyCodeLine{    fleet.initialize(argc, argv);}
\DoxyCodeLine{    }
\DoxyCodeLine{    \textcolor{comment}{// top stores the top hypotheses we have found. We set the number of top to store}}
\DoxyCodeLine{    \textcolor{comment}{// via the command line -\/-\/top=100. Internally, that sets FleetArgs::top, which is used}}
\DoxyCodeLine{    \textcolor{comment}{// as the constructor for TopN. So it only works after you call Fleet.initialize above.}}
\DoxyCodeLine{    \mbox{\hyperlink{class_top_n}{TopN<MyHypothesis>}} top;}
\DoxyCodeLine{    }
\DoxyCodeLine{    \textcolor{comment}{// mydata stores the data for the inference model}}
\DoxyCodeLine{    \textcolor{comment}{// Note that Fleet has these nice string\_to functions which will parse strings in a standard}}
\DoxyCodeLine{    \textcolor{comment}{// format into many of its standard data types. Here, MyHypothesis::data\_t is a comma-\/separated}}
\DoxyCodeLine{    \textcolor{comment}{// list of MyHypothesis::datum\_t's, and each of those is an input:output pair using the }}
\DoxyCodeLine{    \textcolor{comment}{// alphabet}}
\DoxyCodeLine{    \textcolor{keyword}{auto} mydata = string\_to<MyHypothesis::data\_t>(datastr);}
\DoxyCodeLine{    }
\DoxyCodeLine{    \textcolor{comment}{// let's just check that everything in the data is in the alphabet}}
\DoxyCodeLine{    \textcolor{keywordflow}{for}(\textcolor{keyword}{const} \textcolor{keyword}{auto}\& di: mydata) \{}
\DoxyCodeLine{        \textcolor{keywordflow}{for}(\textcolor{keywordtype}{char} c: di.output) \{ \textcolor{comment}{// only checking the outputs are all in the alphabet}}
\DoxyCodeLine{            assert(\mbox{\hyperlink{_strings_8h_a9e236149ce0f5aa64d809fcca5cf1c27}{contains}}(alphabet,c));}
\DoxyCodeLine{        \}}
\DoxyCodeLine{    \}}
\DoxyCodeLine{}
\DoxyCodeLine{    \textcolor{comment}{// tell Fleet's top to print each best hypothesis it finds }}
\DoxyCodeLine{    \textcolor{comment}{// (this can be set with the command line -\/-\/print-\/top-\/best=1)}}
\DoxyCodeLine{    top.\mbox{\hyperlink{class_top_n_a90472852f225e5b851446e4b7ced4856}{print\_best}} = \textcolor{keyword}{true};}
\DoxyCodeLine{     }
\DoxyCodeLine{    \textcolor{comment}{// Create a hypothesis to start our MCMC chain on}}
\DoxyCodeLine{    \textcolor{keyword}{auto} h0 = \mbox{\hyperlink{_random_8h_a3585a6278806f57b964ccd1060f3b8ee}{MyHypothesis::sample}}();}
\DoxyCodeLine{     }
\DoxyCodeLine{    \textcolor{comment}{// Create an MCMC chain}}
\DoxyCodeLine{    \mbox{\hyperlink{class_m_c_m_c_chain}{MCMCChain}} c(h0, \&mydata, top);}
\DoxyCodeLine{     }
\DoxyCodeLine{    \textcolor{comment}{// Actually run -\/-\/ note this uses C++'s new coroutines (like python generators)}}
\DoxyCodeLine{    \textcolor{comment}{// the | print(FleetArgs::print) here will print out every FleetArgs::print steps}}
\DoxyCodeLine{    \textcolor{comment}{// (which is set via -\/-\/print=1000). Defaultly FleetArgs::print=0, which does not print. }}
\DoxyCodeLine{    \textcolor{keywordflow}{for}(\textcolor{keyword}{auto}\& h : c.run(\mbox{\hyperlink{struct_control}{Control}}() | \mbox{\hyperlink{namespace_fleet_args_acf2f80bb2810cea3b3eeef0c4b0edf03}{print}}(\mbox{\hyperlink{namespace_fleet_args_acf2f80bb2810cea3b3eeef0c4b0edf03}{FleetArgs::print}}) ) \{}
\DoxyCodeLine{        top << h; \textcolor{comment}{// add h to top}}
\DoxyCodeLine{         }
\DoxyCodeLine{        \textcolor{comment}{// we can do other stuff with h in here if we want to. }}
\DoxyCodeLine{    \}}
\DoxyCodeLine{}
\DoxyCodeLine{    \textcolor{comment}{// at the end, print the hypotheses we found}}
\DoxyCodeLine{    top.\mbox{\hyperlink{class_top_n_a5064ec2e4e9f1defdc3cb62d9b7ddd00}{print}}();}
\DoxyCodeLine{\}}
\end{DoxyCode}


And finally, we run the actual model. We make an initial hypothesis using My\+Hypothesis\+::sample, which creates a random hypothesis from the prior, we make an \mbox{\hyperlink{class_m_c_m_c_chain}{M\+C\+M\+C\+Chain}}, and we run it. This uses C++\textquotesingle{}s fancy coroutines to let us process the samples as a loop. The c.\+run function takes a \mbox{\hyperlink{struct_control}{Control}} object, which basically specifies the number of steps to run or amount of time to run etc. When \mbox{\hyperlink{struct_control}{Control()}} is called with no arguments, it gets its arguments from the command line. This means that automatically, we can give a commandline arugment like \char`\"{}-\/-\/time=30s\char`\"{} and this fleet program will run for 30 seconds (times can be in days (d), hours (h), minutes (m), seconds (s) or miliseconds (q).

Note that there are several inference schemes, and most (including the examples in Models) use \mbox{\hyperlink{class_parallel_tempering}{Parallel\+Tempering}}, which seems to work best.

As the chain runs, it will place hypotheses into \char`\"{}top\char`\"{} (which defaultly reads the command line argument (e.\+g. \char`\"{}-\/-\/top=25\char`\"{}) to figure out how many of the best hypotheses to store. At the end of this code, we call \mbox{\hyperlink{namespace_fleet_args_acf2f80bb2810cea3b3eeef0c4b0edf03}{top.\+print()}}, which will call the .\mbox{\hyperlink{namespace_fleet_args_acf2f80bb2810cea3b3eeef0c4b0edf03}{print()}} function on everything in top and show them sorted by posterior probability score (remember above we overwrote My\+Hypothesis\+::print in order to have it run the program).

At the end of this program, as the Fleet object is destroyed, it will print out some statistics about the total number of M\+C\+MC steps, total runtime, etc. (This can be turned off by setting \mbox{\hyperlink{namespace_fleet_args_acb1d87c67d763d1edf83ebe1377c948e}{Fleet\+Args\+::print\+\_\+header}}=false). 